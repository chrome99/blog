---
pubDatetime: 2025-03-02T12:00:00Z
title: Building an AI Pipeline That Generates Readable Content
featured: true
draft: false
ogImage: ../../../assets/images/seo-generation-pipeline.png
tags:
  - SEO
  - Scraping
  - LLM
  - Pipeline
description: A practical guide to building a scalable SEO content pipeline using scraping, LLMs, and prompt engineering.
---

![Sketch of a focused man working at a desk with a laptop and creative elements around him.](@/assets/images/seo-generation-pipeline.png)

## Table of contents

## The Problem with AI Content

We live in an age where online cats no longer fall from a wardrobe, or slap each other, or steal icecream from their owners. With the capabilities of AI, cats now do the dishes, ride motorcycles and fight sharks.

Those kinds of visuals are easy to make with some prompt-tinkering. But text is a bit trickier:
LLMs have a distinctive style that’s often unpleasant to read: Verbose, jargon-packed, and wrapped in the dull docility of marketing language. It lacks bite.

Compare this:

> Leveraging cutting-edge algorithms, our innovative solution synergizes deep learning methodologies [...]

With a paragraph written by a [software blogger](https://overreacted.io/what-is-javascript-made-of/):

> Value: The concept of a value is a bit abstract. It’s a “thing”. A value to JavaScript is what a number is to math, or what a point is to geometry. When your program runs, its world is full of values. [...]

However, AI-generated content isn’t impossible to get right. The usual tips - precise style instructions and strong examples - can give you a head start. But what is most crucial to understand is that AI doesn’t create value - it only helps to refine preexisting value.

So if you want to write original content with AI, you are going to need original data.

And if you don't have original data, you can scrape it from the web.

---

## What We’re Trying to Build

The idea is simple: You build a web crawler that loops over a list of URLs and dumps relevant data into JSON files or a database.
The raw data is then processed by a series of prompts, which transform it into a fully readable article. At its core, this is a glorified Object-to-Paragraph / JSON-to-Article pipeline.

### The Tech Stack

- Because you want your website to rank highly on google, it's important to optimize for SEO. Textually, this mostly means using clear headings and relevant keywords.
Performance wise, you need to be careful: excessive client-side rendering and large bundles can slow a page down.
Static site generators like [Astro](https://astro.build/) help by offloading the costly rendering process from the client's browser. Instead this is done at build time, so that at runtime, the server's compute is utilized for quick serving.

- A database is essential for storing and querying all the scraped data. SQLite works well for a quick local setup, but if scalability is a concern, PostgreSQL is the better choice.

- The LLM is the backbone of content generation, and while [OpenAI](https://openai.com/api/) is the obvious go-to, AI Inference Providers (like [DeepInfra](https://deepinfra.com/) or [OpenRouter](https://openrouter.ai/)) allow you to experiment quickly with different open source models.

### Scraping and Cleaning Data

Websites that are ideal for scraping contain data alongside metadata (categories, tags). Metrics are also important for organizing data - likes, comments, shares.

The collected data needs to be cleaned and organized so we can make reasonable assumptins about its contents. This requires filtering, reformatting, and type standartization.

Another challenge is determining whether a scrap of data is legitimately informative - where does it fit on the page? Does it add value or fluff?

## Prompt Engineering: The Hardest Part

I'm generally in favor of Prompt-Tinkering rather than Prompt-Engineering. Prompting isn't the art it is sometimes made out to be. With that in mind:

- The trick is to allow the LLM some creative freedom - just enough to make the writing feel natural, but not so much that it loses structure.
Instead of asking for a paragraph, it’s better to request a response in Markdown format with headings, lists, and tables.

- Instructing the LLM to write conversationally, occasionally ask questions, and avoid excessive jargon improves the readability.
Simplifying language as much as possible forces the LLM to avoid jargon.

- Taking inspiration from well-crafted prompts is helpful ([r/ChatGPTPromptGenuis](https://www.reddit.com/r/ChatGPTPromptGenius/) has many great examples).

## Finishing thoughts
Let me know what you think in the comments below!
